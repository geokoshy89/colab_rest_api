{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use_pytorch_dictionary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6ehkkzeKY52q0JzXCjgKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geokoshy89/colab_rest_api/blob/master/use_pytorch_dictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6cFUiEYY_mD",
        "outputId": "16560ae4-f513-43fb-e919-ba3bf4fa5172"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUxyh5v5ZGKd",
        "outputId": "0de47dc1-65b4-49f0-be29-0309bbd14c6e"
      },
      "source": [
        "!wget https://github.com/futurexskill/ml-model-deployment/raw/main/customer_buy_state_dict_v1.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-10 04:49:50--  https://github.com/futurexskill/ml-model-deployment/raw/main/customer_buy_state_dict_v1.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/customer_buy_state_dict_v1.zip [following]\n",
            "--2021-08-10 04:49:50--  https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/customer_buy_state_dict_v1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1660 (1.6K) [application/zip]\n",
            "Saving to: ‘customer_buy_state_dict_v1.zip’\n",
            "\n",
            "customer_buy_state_ 100%[===================>]   1.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-10 04:49:51 (27.8 MB/s) - ‘customer_buy_state_dict_v1.zip’ saved [1660/1660]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF8bq4mNZUos",
        "outputId": "5f0bbbec-b012-49e6-e8d9-874973b9be3b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "customer_buy_state_dict_v1.zip\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hRUmXKzZdfl",
        "outputId": "90ec2e47-52d7-4a9d-b195-b09b974d1e2b"
      },
      "source": [
        "!unzip customer_buy_state_dict_v1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  customer_buy_state_dict_v1.zip\n",
            "  inflating: customer_buy_state_dict  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOhs9aVVZm5K",
        "outputId": "eaa3bb0b-de81-4c3c-b9be-2c05ac2a7c02"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "customer_buy_state_dict  customer_buy_state_dict_v1.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvcX299pZoOU",
        "outputId": "9523de7c-197a-40bc-beb4-e0ea00342216"
      },
      "source": [
        "!wget https://github.com/futurexskill/ml-model-deployment/raw/main/sc.pickle"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-10 04:51:44--  https://github.com/futurexskill/ml-model-deployment/raw/main/sc.pickle\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/sc.pickle [following]\n",
            "--2021-08-10 04:51:45--  https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/sc.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 502 [application/octet-stream]\n",
            "Saving to: ‘sc.pickle’\n",
            "\n",
            "sc.pickle           100%[===================>]     502  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-10 04:51:45 (16.0 MB/s) - ‘sc.pickle’ saved [502/502]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoL5a6NJZzef"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQrYBudMZ1JX",
        "outputId": "b4f607d2-17ad-4036-c8e9-6a7ce2ca033b"
      },
      "source": [
        "local_scaler=pickle.load(open('sc.pickle','rb'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n0rUIV8aCEP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtKEkSSKaNq7"
      },
      "source": [
        "input_size=2\n",
        "output_size=2\n",
        "hidden_size=10"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoVVD6W4amqv"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1= torch.nn.Linear(input_size,hidden_size)\n",
        "    self.fc2= torch.nn.Linear(hidden_size,hidden_size)\n",
        "    self.fc3= torch.nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self,X):\n",
        "    X=torch.relu(self.fc1(X))\n",
        "    X=torch.relu(self.fc2(X))\n",
        "    X= self.fc3(X)\n",
        "    \n",
        "    return F.log_softmax(X,dim=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsBbsDjfaqoK"
      },
      "source": [
        "new_predictor2=Net()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqIyVJN4bKyl"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXkDWO3SaxaO",
        "outputId": "8e342a88-e332-4f5d-966d-61f13705098b"
      },
      "source": [
        "new_predictor2.load_state_dict(torch.load('customer_buy_state_dict'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntyl4HbPbNC7",
        "outputId": "fd7e543c-925e-4f2d-aa95-22c6ba73ff31"
      },
      "source": [
        "y_cust_40_20000=new_predictor2(torch.from_numpy(local_scaler.transform(np.array([[40,20000]]))).float())\n",
        "y_cust_40_20000"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1102, -2.2600]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}